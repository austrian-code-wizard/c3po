{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains code to generate feedback from the Collie dataset. It depends on having the Collie repo (https://github.com/princeton-nlp/Collie) cloned in the same directory as this notebook. \n",
    "\n",
    "This notebook takes five of the datasets and correspodning tasks from Collie, mainly:\n",
    "wiki_co7/guten_c07 - every sentence contain words (actual: full response contains words)\n",
    "ccnews_c08 - all sentences have 1st word (actual: response starts with given 1st word)\n",
    "wiki_c09 - sentence count, no words (actual: only no words words)\n",
    "\n",
    "However, because it is difficult to distinguish what is a sentence vs an abbreviation with a period and space, we exclude the sentence constraints or modify them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "from pathlib import Path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"Collie\")\n",
    "with open(\"Collie/data/all_data.dill\", \"rb\") as f:\n",
    "    all_data = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = open(\"../feedback/collie.py\", \"w+\")\n",
    "out.write(\"from src.dataset.feedback_utils import Feedback, Scope, Type, Metric, Comparison\\n\\ncollie_feedback = [\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feedback(prompt, domain, categories, metric, metric_value, comparison=\"Comparison.greater_than\"):\n",
    "    return \"\"\"\n",
    "    Feedback(\n",
    "        content=\"{prompt}\",\n",
    "        domain=\"{domain}\",\n",
    "        effect=\"placeholder to fix ValidationError\",\n",
    "        scope=Scope.regional,\n",
    "        categories={categories},\n",
    "        type=Type.quantitative,\n",
    "        metric={metric},\n",
    "        metric_value={metric_value},\n",
    "        comparison={comparison}\n",
    "    ),\n",
    "\"\"\".format(prompt=prompt, domain=domain, categories=categories, metric=metric, metric_value=metric_value, comparison=comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "key = \"wiki_c07\"\n",
    "chosen = np.random.choice(np.arange(len(all_data[key])), size=38, replace=False)\n",
    "for i in chosen:\n",
    "    obj = all_data[key][i]\n",
    "    topic = obj['metadata'][\"title\"]\n",
    "    words = obj['prompt'].split(\"containing the word\")[1][:-1].strip()\n",
    "    prompt = f\"When talking about {topic}, make sure all sentences contain the words {words}\"\n",
    "    domain = f\"Talking about {topic}\"\n",
    "    out_str = get_feedback(prompt, domain, f\"['collie', '{key}']\", \"Metric.contains_all_strings\", \"\"\"[{words}]\"\"\".format(words=words))\n",
    "    out.write(out_str + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "key = \"ccnews_c08/wiki_c08\"\n",
    "arr = []\n",
    "arr.extend(all_data[\"wiki_c08\"])\n",
    "arr.extend(all_data[\"ccnews_c08\"])\n",
    "chosen = np.random.choice(np.arange(len(arr)), size=24, replace=False)\n",
    "print(len(arr))\n",
    "for i in chosen:\n",
    "    obj = arr[i]\n",
    "    topic = obj['metadata'][\"title\"]\n",
    "    words = obj['prompt'].split(\"1st word to be\")[1][:-1].strip()\n",
    "    prompt = f\"When talking about {topic}, make sure the first sentences has a 1st word of {words}\"\n",
    "    domain = f\"Talking about {topic}\"\n",
    "    out_str = get_feedback(prompt, domain, f\"['collie', '{key}']\", \"Metric.first_words\",words.lower())\n",
    "    out.write(out_str + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"wiki_c09\"\n",
    "chosen = np.random.choice(np.arange(len(all_data[key])), size=38, replace=False)\n",
    "for i in chosen:\n",
    "    obj = all_data[key][i]\n",
    "    topic = obj['metadata'][\"title\"]\n",
    "    targets = obj[\"targets\"]\n",
    "    words = \"\\'\" + \"', '\".join(targets[1:]) + \"'\"\n",
    "    prompt = f\"When talking about {topic}, do not use the words {words}\"\n",
    "    domain = f\"Talking about {topic}\"\n",
    "    out_str = get_feedback(prompt, domain, f\"['collie', '{key}']\", \"Metric.contains_none_strings\", f\"{targets[1:]}\")\n",
    "    out.write(out_str + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.write(\"]\\n\")\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfl2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
